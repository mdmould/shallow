{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6709927-160d-49ce-b985-3ea354776d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from corner import corner\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "tfk = tf.keras\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0846058f-1231-40de-bc64-80e9efada76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_powerlaw(n_samples, slope, lo, hi):\n",
    "    \n",
    "    x = np.random.uniform(size=n_samples)\n",
    "    \n",
    "    return (lo**(slope+1) + x * (hi**(slope+1) - lo**(slope+1)))**(1/(slope+1))\n",
    "\n",
    "def sample_data(n_dim, n_samples, slope, lo, hi, loc, scale, bounded_idxs=[1, 2]):\n",
    "    \n",
    "    n_bounded = len(bounded_idxs)\n",
    "    n_unbounded = n_dim - n_bounded\n",
    "    unbounded_idxs = list(set(range(n_dim)) - set(bounded_idxs))\n",
    "    data = np.zeros([n_samples, n_dim])\n",
    "    data[:, unbounded_idxs] = np.random.normal(\n",
    "        loc=loc, scale=scale, size=[n_samples, n_unbounded],\n",
    "        )\n",
    "    data[:, bounded_idxs] = sample_powerlaw(\n",
    "        [n_samples, n_bounded], slope, lo, hi,\n",
    "        )\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1647091f-6254-4449-a690-2f90ec8b2466",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim = 2\n",
    "n_samples = 10000\n",
    "slope = 1\n",
    "lo = 0\n",
    "hi = 1\n",
    "loc = 2\n",
    "scale = 3\n",
    "bounded_idxs = [1]\n",
    "\n",
    "data = sample_data(n_dim, n_samples, slope, lo, hi, loc, scale, bounded_idxs)\n",
    "\n",
    "corner(data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45149b66-98ee-4ddd-9b3d-5a09a90377ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to permute between flows\n",
    "# For n_dim > 2, there are multiple choices\n",
    "# But we have to ensure all outputs are moved\n",
    "\n",
    "def all_permuted(n_dim):\n",
    "    \n",
    "    permutations = np.array(list(itertools.permutations(range(n_dim))))\n",
    "    permuted = ~np.any(permutations == list(range(n_dim)), axis=1)\n",
    "    \n",
    "    return permutations[permuted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aae6777-7f57-444f-abae-f54330224600",
   "metadata": {},
   "outputs": [],
   "source": [
    "permutations = all_permuted(n_dim)\n",
    "permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc494dbf-c630-477d-a68f-4878f847ae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_flows = 5\n",
    "n_layers = 1\n",
    "n_neurons = 128\n",
    "activation = 'relu' #tfa.activations.rrelu\n",
    "\n",
    "bijectors = []\n",
    "\n",
    "# We transform the bounded outputs at the end\n",
    "# Adjust shift and scale to whatever domain you need\n",
    "blockwise_bijectors = []\n",
    "for i in range(n_dim):\n",
    "    if i in bounded_idxs:\n",
    "        sigmoid = tfb.Chain(\n",
    "            #[tfb.Tanh(), tfb.Shift(shift=1.), tfb.Scale(scale=.5)],\n",
    "            [tfb.Scale(scale=.5), tfb.Shift(shift=1.), tfb.Tanh()],\n",
    "            )\n",
    "        blockwise_bijectors.append(sigmoid)\n",
    "    else:\n",
    "        blockwise_bijectors.append(tfb.Identity())\n",
    "blockwise_bijector = tfb.Blockwise(blockwise_bijectors, block_sizes=[1]*n_dim)\n",
    "bijectors.append(blockwise_bijector)\n",
    "\n",
    "for i in range(n_flows):\n",
    "    bijectors.append(tfb.MaskedAutoregressiveFlow(tfb.AutoregressiveNetwork(\n",
    "        params=2,\n",
    "        hidden_units=[n_neurons]*n_layers,\n",
    "        activation=activation,\n",
    "        )))\n",
    "    #bijectors.append(tfb.BatchNormalization(training=True))\n",
    "    bijectors.append(tfb.Permute(list(reversed(range(n_dim)))))\n",
    "\n",
    "bijector = tfb.Chain(bijectors)\n",
    "distribution = tfd.MultivariateNormalDiag(loc=[0]*n_dim)\n",
    "nf = tfd.TransformedDistribution(distribution=distribution, bijector=bijector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4714dee-72cb-4b08-8687-f2ea702659fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the correct dimensions are bounded\n",
    "nf.sample(10000).numpy().min(axis=0), nf.sample(10000).numpy().max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ac6b53-5ccc-40a6-abe8-4fa3fc947b42",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 100\n",
    "learning_rate = 1e-3\n",
    "\n",
    "x = tf.keras.Input(shape=[n_dim], dtype=tf.float32)\n",
    "log_prob = nf.log_prob(x)\n",
    "\n",
    "model = tf.keras.Model(\n",
    "    inputs=x,\n",
    "    outputs=log_prob,\n",
    "    )\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=learning_rate),\n",
    "    loss=lambda _, log_prob: -log_prob,\n",
    "    )\n",
    "\n",
    "# callbacks = [\n",
    "#     tfk.callbacks.ModelCheckpoint(\n",
    "#         filepath='./5_nonconditional.hdf5',\n",
    "#         monitor='val_loss',\n",
    "#         mode='min',\n",
    "#         save_weights_only=True,\n",
    "#         save_best_only=True,\n",
    "#         save_freq='epoch',\n",
    "#         verbose=1,\n",
    "#         ),\n",
    "#     tfk.callbacks.CSVLogger(\n",
    "#         './nf2.csv',\n",
    "#         ),\n",
    "#     tfk.callbacks.EarlyStopping(\n",
    "#         monitor='val_loss',\n",
    "#         min_delta=0,\n",
    "#         patience=10,\n",
    "#         mode='min',\n",
    "#         baseline=None,\n",
    "#         restore_best_weights=False,\n",
    "#         verbose=1,\n",
    "#         ),\n",
    "#     ]\n",
    "\n",
    "steps_per_epoch = n_samples // batch_size\n",
    "\n",
    "result = model.fit(\n",
    "    x=data, y=np.zeros(n_samples),\n",
    "    validation_data=[\n",
    "        sample_data(n_dim, n_samples, slope, lo, hi, loc, scale, bounded_idxs),\n",
    "        np.zeros(n_samples),\n",
    "        ],\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    #callbacks=callbacks,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55106926-7c1e-4c24-ba8d-61c195ab3209",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(result.history['loss'])\n",
    "plt.plot(result.history['val_loss']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a833cee-c70d-4f4f-81f4-8f3efd0a6e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should be like the training data\n",
    "corner(nf.sample(n_samples).numpy());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e82fce-60f3-4ac5-8c4c-03a3bd9c41a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should be a Gaussian\n",
    "samples = sample_data(\n",
    "    n_dim, n_samples, slope, lo, hi, loc, scale, bounded_idxs,\n",
    "    )\n",
    "corner(bijector.inverse(samples).numpy());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8b6c99-f651-4c90-83b7-4d4bad917a19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shallow",
   "language": "python",
   "name": "shallow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74879eba-a0f1-4807-ab97-e04033b65672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from corner import corner\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "tfk = tf.keras\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d7ba76-628f-472c-a49e-2a4889bcfe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerlaw(x, slope, lo, hi):\n",
    "    \n",
    "    return (\n",
    "        (x >= lo) * (x <= hi)\n",
    "        * x**slope\n",
    "        * (slope+1) / (hi**(slope+1) - lo**(slope+1))\n",
    "        )\n",
    "\n",
    "def sample_powerlaw(n_samples, slope, lo, hi):\n",
    "    \n",
    "    x = np.random.uniform(size=n_samples)\n",
    "    \n",
    "    return (lo**(slope+1) + x * (hi**(slope+1) - lo**(slope+1)))**(1/(slope+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b750da-2706-411e-9d2a-e99e4fa73cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_slopes = 10\n",
    "n_train = 10000\n",
    "n_valid = 10000\n",
    "\n",
    "slopes_lo = 0\n",
    "slopes_hi = 5\n",
    "data_lo = 0\n",
    "data_hi = 1\n",
    "n_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0df89fa-8d54-405c-a23d-ea063aae35b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "slopes_train = np.random.uniform(\n",
    "    low=slopes_lo, high=slopes_hi, size=n_slopes,\n",
    "    )\n",
    "slopes_valid = np.random.uniform(\n",
    "    low=slopes_lo, high=slopes_hi, size=n_slopes,\n",
    "    )\n",
    "\n",
    "data_train = sample_powerlaw(\n",
    "    (n_slopes, n_train, n_dim),\n",
    "    slopes_train[:, None, None],\n",
    "    data_lo,\n",
    "    data_hi,\n",
    "    )\n",
    "data_valid = sample_powerlaw(\n",
    "    (n_slopes, n_valid, n_dim),\n",
    "    slopes_valid[:, None, None],\n",
    "    data_lo,\n",
    "    data_hi,\n",
    "    )\n",
    "\n",
    "slopes_train.shape, slopes_valid.shape, data_train.shape, data_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e903063-c7f9-49d5-9c44-2127fa1bfaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "corner(data_train[i]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f234135-1d4c-4017-87f1-fe108540b1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "slopes_train = np.repeat(slopes_train[:, None, None], n_train, axis=1)\n",
    "slopes_valid = np.repeat(slopes_valid[:, None, None], n_valid, axis=1)\n",
    "\n",
    "slopes_train.shape, slopes_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ae62ac-7df0-43e9-a1ee-54d87d8238b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "slopes_train = slopes_train.reshape(-1, 1)\n",
    "slopes_valid = slopes_valid.reshape(-1, 1)\n",
    "data_train = data_train.reshape(-1, n_dim)\n",
    "data_valid = data_valid.reshape(-1, n_dim)\n",
    "\n",
    "slopes_train.shape, slopes_valid.shape, data_train.shape, data_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35a5a6d-bfa0-4a14-a5fb-8f56ee1d024b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Norm:\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        \n",
    "        self.mean = np.mean(data, axis=0)\n",
    "        self.std = np.std(data, axis=0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        return (x - self.mean) / self.std\n",
    "    \n",
    "    def inverse(self, y):\n",
    "        \n",
    "        return y * self.std + self.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cab6ff-919b-44f2-8f89-f072a8788e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = False\n",
    "\n",
    "if normalize:\n",
    "    \n",
    "    slopes_norm = Norm(slopes_train)\n",
    "    slopes_train = slopes_norm.forward(slopes_train)\n",
    "    slopes_valid = slopes_norm.forward(slopes_valid)\n",
    "    \n",
    "    data_norm = Norm(data_train)\n",
    "    data_train = data_norm.forward(data_train)\n",
    "    data_valid = data_norm.forward(data_valid)\n",
    "    \n",
    "    i = 0\n",
    "    corner(data_train[n_train*i:n_train*(i+1)]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1caa530-4d50-4d8b-ae74-0f0bab61eae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/tensorflow/probability/issues/1410\n",
    "# https://github.com/tensorflow/probability/issues/1006#issuecomment-663141106\n",
    "\n",
    "import re\n",
    "\n",
    "def make_bijector_kwargs(bijector, name_to_kwargs):\n",
    "    if hasattr(bijector, 'bijectors'):\n",
    "        return {b.name: make_bijector_kwargs(b, name_to_kwargs) for b in bijector.bijectors}\n",
    "    else:\n",
    "        for name_regex, kwargs in name_to_kwargs.items():\n",
    "            if re.match(name_regex, bijector.name):\n",
    "                return kwargs\n",
    "    return {}\n",
    "\n",
    "def make_kwargs(flow, condition):\n",
    "    \n",
    "    name_to_kwargs = {'maf.': {'conditional_input': condition}}\n",
    "    \n",
    "    return make_bijector_kwargs(flow.bijector, name_to_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea15411-64f7-4484-a2f7-268b18d2da3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_flows = 10\n",
    "n_layers = 1\n",
    "n_units = 1024\n",
    "activation = 'relu'\n",
    "\n",
    "bijectors = []\n",
    "\n",
    "# if normalize:\n",
    "#     shift = -float(abs(data_norm.forward(data_lo)[0]))\n",
    "#     scale = float(data_norm.forward(data_hi)[0] - data_norm.forward(data_lo)[0])\n",
    "#     bijectors.append(tfb.Shift(shift=shift))\n",
    "#     bijectors.append(tfb.Scale(scale=scale))\n",
    "# bijectors.append(tfb.Scale(scale=.5))\n",
    "# bijectors.append(tfb.Shift(shift=1.))\n",
    "# bijectors.append(tfb.Tanh())\n",
    "\n",
    "if normalize:\n",
    "    shifts = data_norm.forward(data_lo).astype(np.float32)\n",
    "    scales = (data_norm.forward(data_hi) - data_norm.forward(data_lo)).astype(np.float32)\n",
    "    blockwise_bijectors = []\n",
    "    for shift, scale in zip(shifts, scales):\n",
    "        blockwise_bijectors.append(\n",
    "            tfb.Chain([tfb.Shift(shift=shift), tfb.Scale(scale=scale)]),\n",
    "            )\n",
    "    blockwise_bijector = tfb.Blockwise(blockwise_bijectors, block_sizes=[1]*n_dim)\n",
    "    bijectors.append(blockwise_bijector)\n",
    "\n",
    "bijectors.append(tfb.Scale(scale=.5))\n",
    "bijectors.append(tfb.Shift(shift=1.))\n",
    "bijectors.append(tfb.Tanh())\n",
    "\n",
    "for i in range(n_flows):\n",
    "    \n",
    "    made = tfb.AutoregressiveNetwork(\n",
    "        params=2,\n",
    "        event_shape=(n_dim,),\n",
    "        conditional=True,\n",
    "        conditional_event_shape=(1,),\n",
    "        # conditional_input_layers='all_layers',\n",
    "        hidden_units=[n_units]*n_layers,\n",
    "        # input_order='left-to-right',\n",
    "        # hidden_degrees='equal',\n",
    "        activation=activation,\n",
    "        use_bias=True,\n",
    "        #kernel_initializer='zeros',\n",
    "        kernel_initializer=tfk.initializers.RandomNormal(mean=0., stddev=.01),\n",
    "        # kernel_initializer=tfk.initializers.Orthogonal(1e-2),\n",
    "        bias_initializer='zeros',\n",
    "        # kernel_regularizer=tf.keras.regularizers.L2(l2=1e-6),\n",
    "        # kernel_regularizer=tf.keras.regularizers.L1L2(l1=1e-2, l2=1e-2),\n",
    "        # bias_regularizer=None,\n",
    "        # kernel_constraint=None,\n",
    "        # bias_constraint=None,\n",
    "        # validate_args=False,\n",
    "        # name=f'made{i}'\n",
    "        )\n",
    "    maf = tfb.MaskedAutoregressiveFlow(made, name=f'maf{i}')\n",
    "    bijectors.append(maf)\n",
    "    \n",
    "    # norm = tfb.BatchNormalization()\n",
    "    # norm = tfb.Invert(tfb.BatchNormalization())\n",
    "    # bijectors.append(norm)\n",
    "    \n",
    "    # if i < n_flows-1:\n",
    "    permute = tfb.Permute(list(reversed(range(n_dim))))\n",
    "    bijectors.append(permute)\n",
    "\n",
    "bijector = tfb.Chain(bijectors)\n",
    "distribution = tfd.Sample(tfd.Normal(loc=0., scale=1.), sample_shape=[n_dim])\n",
    "nf = tfd.TransformedDistribution(distribution=distribution, bijector=bijector)\n",
    "\n",
    "x = tfk.Input(shape=(n_dim,), dtype=tf.float32)\n",
    "c = tfk.Input(shape=(1,), dtype=tf.float32)\n",
    "\n",
    "log_prob = nf.log_prob(\n",
    "    x, bijector_kwargs=make_kwargs(nf, c),\n",
    "    )\n",
    "\n",
    "model = tfk.Model([x, c], log_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4787b6-efbf-4566-9cde-1ace56254d31",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 100\n",
    "learning_rate = 1e-4\n",
    "\n",
    "model.compile(\n",
    "    # optimizer=tf.optimizers.Adam(learning_rate=learning_rate),\n",
    "    optimizer=tfa.optimizers.AdamW(\n",
    "        weight_decay=1e-6, learning_rate=learning_rate,\n",
    "        ),\n",
    "    loss=lambda _, log_prob: -log_prob,\n",
    "    )\n",
    "\n",
    "result = model.fit(\n",
    "    x=[data_train, slopes_train],\n",
    "    y=np.zeros(n_train*n_slopes, dtype=np.float32),\n",
    "    validation_data=(\n",
    "        [data_valid, slopes_valid],\n",
    "        np.zeros(n_valid*n_slopes, dtype=np.float32),\n",
    "        ),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16e4262-e1f7-437e-a3fc-a9b37b85b598",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(result.history['loss'][0:])\n",
    "plt.plot(result.history['val_loss'][0:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e5943c-a457-4602-bac5-9b5a74cf8580",
   "metadata": {},
   "outputs": [],
   "source": [
    "slope = 0.5\n",
    "n = 10000\n",
    "\n",
    "condition = slope * np.ones((n, 1))\n",
    "if normalize:\n",
    "    condition = slopes_norm.forward(condition)\n",
    "bijector_kwargs = make_kwargs(nf, condition)\n",
    "\n",
    "samples = nf.sample(n, bijector_kwargs=bijector_kwargs).numpy()\n",
    "if normalize:\n",
    "    samples = data_norm.inverse(samples)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=n_dim, ncols=n_dim, figsize=(7, 7))\n",
    "corner(samples, fig=fig, hist_kwargs=dict(density=True))\n",
    "x = np.linspace(data_lo, data_hi, 1000)\n",
    "for i in range(n_dim):\n",
    "    axs[i, i].plot(x, (slope+1)*x**slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf02184-e3fd-4842-9ae3-71dbe3721e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "slope = 0\n",
    "n = 10000\n",
    "\n",
    "condition = slope * np.ones((n, 1))\n",
    "if normalize:\n",
    "    condition = slopes_norm.forward(condition)\n",
    "bijector_kwargs = make_kwargs(nf, condition)\n",
    "\n",
    "samples = sample_powerlaw([n, n_dim], slope, data_lo, data_hi).astype(np.float32)\n",
    "if normalize:\n",
    "    samples = data_norm.forward(samples)\n",
    "samples = nf.bijector.inverse(samples, **bijector_kwargs).numpy()\n",
    "\n",
    "fig, axs = plt.subplots(nrows=n_dim, ncols=n_dim, figsize=(7, 7))\n",
    "corner(samples, fig=fig, hist_kwargs=dict(density=True))\n",
    "x = np.linspace(-5, 5, 1000)\n",
    "for i in range(n_dim):\n",
    "    axs[i, i].plot(x, np.exp(-.5*x**2)/(2*np.pi)**.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dd644f-892b-42c0-b1fd-493bb0dd21ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad00f175-c036-4416-b205-54f125d453fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493db32f-7c76-4d82-a79e-925fa9020524",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import trapezoid\n",
    "\n",
    "def cartesian_product(axes):\n",
    "\n",
    "    return np.array(np.meshgrid(*axes, indexing='ij')).reshape(len(axes), -1)\n",
    "\n",
    "def integrate_nd(y, x, dims=None):\n",
    "    \n",
    "    assert len(np.shape(y)) == len(x)\n",
    "    n_dim = len(x)\n",
    "    for dim in range(n_dim):\n",
    "        assert np.shape(y)[dim] == len(x[dim])\n",
    "        \n",
    "    if dims is None:\n",
    "        dims = np.arange(n_dim)\n",
    "        \n",
    "    for dim in np.flip(np.sort(dims)):\n",
    "        y = trapezoid(y, x[dim], axis=dim)\n",
    "        \n",
    "    return y\n",
    "\n",
    "def kl_trapezoid(p, q, x):\n",
    "    \n",
    "    return integrate_nd(p*(np.log(p)-np.log(q)), x)\n",
    "\n",
    "def kl_montecarlo(p, q):\n",
    "    \n",
    "    return np.sum(np.log(p)-np.log(q)) / len(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223cdf63-33fd-4c87-a68b-5a1a5e7bc0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "slope = 0.\n",
    "n = 100\n",
    "\n",
    "condition = slope * np.ones((n**n_dim, 1))\n",
    "bijector_kwargs = make_kwargs(nf, condition)\n",
    "\n",
    "x = np.linspace(1e-3, 1-1e-3, n)\n",
    "axes = [x, x]\n",
    "grid = cartesian_product(axes)\n",
    "\n",
    "p = np.product(powerlaw(grid, slope, lo, hi), axis=0).reshape(n, n)\n",
    "q = nf.prob(grid.T, bijector_kwargs=bijector_kwargs).numpy().reshape(n, n)\n",
    "\n",
    "kl_trapezoid(p, q, axes), kl_trapezoid(q, p, axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393ebc8a-c32a-4980-b433-f1edf688f6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "slope = 0.\n",
    "n = 10000\n",
    "\n",
    "condition = slope * np.ones((n, 1))\n",
    "bijector_kwargs = make_kwargs(nf, condition)\n",
    "\n",
    "samples = sample_powerlaw((n, n_dim), slope, lo, hi)\n",
    "p = np.product(powerlaw(samples, slope, lo, hi), axis=1)\n",
    "q = nf.prob(samples, bijector_kwargs=bijector_kwargs).numpy()\n",
    "\n",
    "kl_montecarlo(p, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8c591b-750d-4b4f-97bc-e9ee53d70c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "slope = 0.\n",
    "n = 10000\n",
    "\n",
    "condition = slope * np.ones((n, 1))\n",
    "bijector_kwargs = make_kwargs(nf, condition)\n",
    "\n",
    "samples = samples = nf.sample(n, bijector_kwargs=bijector_kwargs).numpy()\n",
    "p = nf.prob(samples, bijector_kwargs=bijector_kwargs).numpy()\n",
    "q = np.product(powerlaw(samples, slope, lo, hi), axis=1)\n",
    "\n",
    "kl_montecarlo(p, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8277cf-5b01-4104-adfe-bb3d2c2fd007",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shallow",
   "language": "python",
   "name": "shallow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

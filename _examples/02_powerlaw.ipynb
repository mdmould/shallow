{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e060f23d-7d63-47ee-bb77-2798d81055db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from corner import corner\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "tfk = tf.keras\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45599ed-a821-4d07-a77b-4e4a2a50bd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerlaw(x, slope, lo, hi):\n",
    "    \n",
    "    return (\n",
    "        (x >= lo) * (x <= hi) \n",
    "        * x**slope * (slope+1) \n",
    "        / (hi**(slope+1) - lo**(slope+1))\n",
    "        )\n",
    "\n",
    "def sample_powerlaw(n_samples, slope, lo, hi):\n",
    "    \n",
    "    return (\n",
    "        np.random.uniform(size=n_samples) * (hi**(slope+1) - lo**(slope+1))\n",
    "        + lo**(slope+1)\n",
    "        )**(1/(slope+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b669f5d-7c1d-4e8f-a236-4dae7eec099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim = 2\n",
    "n_samples = 10000\n",
    "slope = 1\n",
    "lo = 0\n",
    "hi = 1\n",
    "\n",
    "data = sample_powerlaw([n_samples, n_dim], 1, 0, 1)\n",
    "\n",
    "corner(data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4ed872-86ac-451c-af85-f2d73f70ba86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_permuted(n_dim):\n",
    "    \n",
    "    permutations = np.array(list(itertools.permutations(range(n_dim))))\n",
    "    permuted = ~np.any(permutations == list(range(n_dim)), axis=1)\n",
    "    \n",
    "    return permutations[permuted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727bf303-7b9f-47d5-a8bf-a1ead686f799",
   "metadata": {},
   "outputs": [],
   "source": [
    "permutations = all_permuted(n_dim)\n",
    "permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a9c275-bd8b-4ebe-b64f-e53c0b040341",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_flows = 10\n",
    "n_layers = 1\n",
    "n_neurons = 1024\n",
    "\n",
    "# The function u = f(x), where x is the data and u is the base variate\n",
    "bijectors = []\n",
    "\n",
    "# We transform at the end with a logistic function\n",
    "# This ensures all samples are in [0, 1]\n",
    "bijectors.append(tfb.Scale(scale=.5))\n",
    "bijectors.append(tfb.Shift(shift=1.))\n",
    "bijectors.append(tfb.Tanh())\n",
    "\n",
    "for i in range(n_flows):\n",
    "    bijectors.append(tfb.MaskedAutoregressiveFlow(tfb.AutoregressiveNetwork(\n",
    "        params=2,\n",
    "        hidden_units=[n_neurons]*n_layers,\n",
    "        activation='relu',\n",
    "        ))\n",
    "        )\n",
    "    #bijectors.append(tfb.BatchNormalization(training=True))\n",
    "    bijectors.append(tfb.Permute(list(reversed(range(n_dim)))))\n",
    "\n",
    "bijector = tfb.Chain(bijectors)\n",
    "distribution = tfd.MultivariateNormalDiag(loc=[0]*n_dim)\n",
    "nf = tfd.TransformedDistribution(distribution=distribution, bijector=bijector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af2e647-fbee-44f5-bffb-fcf7a5a191ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check it's bounded\n",
    "nf.sample(10000).numpy().min(), nf.sample(10000).numpy().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f49bb7-d89e-4c4b-97ce-9d9009dbc096",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 100\n",
    "learning_rate = 1e-3\n",
    "\n",
    "x = tf.keras.Input(shape=[n_dim], dtype=tf.float32)\n",
    "log_prob = nf.log_prob(x)\n",
    "\n",
    "model = tf.keras.Model(\n",
    "    inputs=x,\n",
    "    outputs=log_prob,\n",
    "    )\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.optimizers.Adam(learning_rate=learning_rate),\n",
    "    loss=lambda _, log_prob: -log_prob,\n",
    "    )\n",
    "\n",
    "steps_per_epoch = n_samples // batch_size\n",
    "\n",
    "result = model.fit(\n",
    "    x=data, y=np.zeros(n_samples),\n",
    "    epochs=epochs, \n",
    "    batch_size=batch_size,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca3e5d8-1578-43d5-a1aa-027715cafb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(result.history['loss']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63d030d-b9fc-433e-baa0-fb017d91bd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should be like the training data\n",
    "corner(nf.sample(n_samples).numpy(), truths=[1]*n_dim);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89534519-4658-4db6-a270-96c1da8dc00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can I call bijector directly?\n",
    "corner(\n",
    "    nf.bijector.forward(distribution.sample(10000)).numpy(),\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d58ad4-16ba-4543-ba73-0b4e4a80d537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should be a Gaussian\n",
    "fig = corner(\n",
    "    nf.bijector.inverse(\n",
    "        sample_powerlaw([n_samples, n_dim], slope, lo, hi).astype(np.float32),\n",
    "        ).numpy(),\n",
    "    range=[[-4, 4]]*n_dim,\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0698dcbe-73a7-41c3-beed-b0e597428aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_dim == 1:\n",
    "    \n",
    "    points = np.linspace(0, 1, 200)\n",
    "    probs = np.exp(nf.log_prob(points[:, None]))\n",
    "    \n",
    "    plt.plot(points, powerlaw(points, slope, lo, hi))\n",
    "    plt.plot(points, probs);\n",
    "\n",
    "elif n_dim == 2:\n",
    "\n",
    "    points = np.linspace(-.5, 1.5, 200)\n",
    "    axes = np.meshgrid(*[points]*n_dim)\n",
    "    grid = np.concatenate([ax.reshape(-1, 1) for ax in axes], axis=1)\n",
    "\n",
    "    probs = np.exp(nf.log_prob(grid)).reshape(axes[0].shape)\n",
    "\n",
    "    plt.imshow(\n",
    "        probs,\n",
    "        aspect='equal',\n",
    "        origin='lower',\n",
    "        extent=[-.5, 1.5, -.5, 1.5],\n",
    "        );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7decb0b2-5b20-4565-a9c4-adb364d7af99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "probflow",
   "language": "python",
   "name": "probflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
